{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f2136e",
   "metadata": {
    "_cell_guid": "bfd3d3cc-74de-4b87-8e43-e9a56157f193",
    "_uuid": "a794e192-bd8d-4eac-8ad5-7e1c719d929e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006026,
     "end_time": "2025-12-08T13:26:34.863794",
     "exception": false,
     "start_time": "2025-12-08T13:26:34.857768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b308ad0",
   "metadata": {
    "_cell_guid": "06883fe4-dbb9-4c13-bd89-f684a1b1864c",
    "_uuid": "9dfc6e10-323d-402d-8a9a-e0d61357d1c7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004675,
     "end_time": "2025-12-08T13:26:34.873395",
     "exception": false,
     "start_time": "2025-12-08T13:26:34.868720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f863bd88",
   "metadata": {
    "_cell_guid": "f3dd8e1d-6723-47b9-992a-827295a0ba5b",
    "_uuid": "94e083b7-791a-402d-b4e7-b16da1040857",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:34.884733Z",
     "iopub.status.busy": "2025-12-08T13:26:34.883981Z",
     "iopub.status.idle": "2025-12-08T13:26:39.699281Z",
     "shell.execute_reply": "2025-12-08T13:26:39.698465Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.822955,
     "end_time": "2025-12-08T13:26:39.700991",
     "exception": false,
     "start_time": "2025-12-08T13:26:34.878036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "# Required for local testing/submission environment\n",
    "import kaggle_evaluation.default_inference_server\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118921f1",
   "metadata": {
    "_cell_guid": "804f8dea-a865-442c-9e45-b28cec92d845",
    "_uuid": "b66da7e1-e856-49ec-bebe-6d79c35c4499",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004725,
     "end_time": "2025-12-08T13:26:39.711145",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.706420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Project Directory Structure**\n",
    "\n",
    "*(From template)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da52ae5a",
   "metadata": {
    "_cell_guid": "4604193b-bdf1-4cde-b929-aae3fde55c33",
    "_uuid": "96db35a1-425c-4eac-a327-2d2b17052afe",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.722368Z",
     "iopub.status.busy": "2025-12-08T13:26:39.721558Z",
     "iopub.status.idle": "2025-12-08T13:26:39.731701Z",
     "shell.execute_reply": "2025-12-08T13:26:39.730717Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017395,
     "end_time": "2025-12-08T13:26:39.733165",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.715770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/hull-tactical-market-prediction/train.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/test.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_inference_server.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef217902",
   "metadata": {
    "_cell_guid": "29dd6571-3bab-422f-8568-0c4528bf6b65",
    "_uuid": "96256866-8947-4dac-b50f-2cb9b735ecf6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.00484,
     "end_time": "2025-12-08T13:26:39.743007",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.738167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19f19e6",
   "metadata": {
    "_cell_guid": "abbc3717-442b-466a-acc8-5611558aba25",
    "_uuid": "d34c6198-eeef-4b31-b7e9-9c36ea2d0b90",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.754021Z",
     "iopub.status.busy": "2025-12-08T13:26:39.753688Z",
     "iopub.status.idle": "2025-12-08T13:26:39.760516Z",
     "shell.execute_reply": "2025-12-08T13:26:39.759678Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014264,
     "end_time": "2025-12-08T13:26:39.761957",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.747693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============ PATHS ============\n",
    "DATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "MODEL_PATH = '/tmp/model_data.joblib'\n",
    "TARGET_COL = 'market_forward_excess_returns'\n",
    "EXCLUDE_COLS = ['date_id', 'forward_returns', 'risk_free_rate',TARGET_COL]\n",
    "TARGET_COL_TEST = 'lagged_market_forward_excess_returns'\n",
    "EXCLUDE_COLS_TEST = ['date_id', 'is_scored','lagged_forward_returns','lagged_risk_free_rate',TARGET_COL_TEST]\n",
    "\n",
    "# ========== FILL NA CONFIG ==============\n",
    "EWMA_SPAN: int = 20\n",
    "\n",
    "# ================ THRESHOLD & SWEEP OPTIONS (MODIFIED) ===================\n",
    "PI_SCORER_THRESHOLD = 0.001               # PI Threshold for ASR SCORER \n",
    "TOP_K_OPTIONS = [3, 5, 8, 10, 15]         # Feature selection by count\n",
    "K_POS_OPTIONS = [10, 25, 50, 75, 100, 150, 200]      # Tanh signal optimization for (prediction>0)\n",
    "K_NEG_OPTIONS = [500, 1000, 1500, 2000]              # Tanh signal optimization for (prediction<0)\n",
    "MAX_ITER_OPTIONS = [500, 750, 1000, 1250, 1500, 2000]  #HGBR Max iteration sweeping option\n",
    "\n",
    "# ============ MODEL CONFIGS ============\n",
    "RANDOM_STATE = 42 \n",
    "HGBR_LEARNING_RATE: float = 0.05\n",
    "HGBR_MAX_DEPTH: int = 5 \n",
    "HGBR_L2_REG: float = 0.1\n",
    "HGBR_EARLY_STOPPING: bool = False \n",
    "\n",
    "# ============ RETURNS TO SIGNAL CONFIGS ============\n",
    "MIN_SIGNAL: float = 0.0                         # Minimum value for submission \n",
    "MAX_SIGNAL: float = 2.0                         # Maximum value for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2efecbe",
   "metadata": {
    "_cell_guid": "00a97942-5efa-4d23-a574-3367a141b5e4",
    "_uuid": "fbe3eaec-3eab-4fc3-8ca2-f443fd3302a8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004828,
     "end_time": "2025-12-08T13:26:39.771709",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.766881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ee9a7",
   "metadata": {
    "_cell_guid": "31df4dbe-9dd0-42a1-a78f-ca75e5c3e6fd",
    "_uuid": "9e3f79d6-714f-4805-b22a-4bd337b6ae89",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004716,
     "end_time": "2025-12-08T13:26:39.781407",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.776691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Cleaning and Imputation for Training Data**\n",
    "\n",
    "1. Delete features with a lot of measing values\n",
    "2. Fill missing values with EWMA (and mean in the case where the first few rows are NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4808fc05",
   "metadata": {
    "_cell_guid": "ff72732f-9112-44da-aff1-172be815ddfc",
    "_uuid": "281068ea-c099-4557-84f7-6dd78037cf8d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.793494Z",
     "iopub.status.busy": "2025-12-08T13:26:39.793193Z",
     "iopub.status.idle": "2025-12-08T13:26:39.802614Z",
     "shell.execute_reply": "2025-12-08T13:26:39.801896Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017822,
     "end_time": "2025-12-08T13:26:39.803845",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.786023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_and_impute_data_training(df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Handles missing values: drops columns with >30% missing, then imputes via EWMA/Mean.\n",
    "    \"\"\"\n",
    "    global EXCLUDE_COLS\n",
    "    \n",
    "    print(\"==================================================\")\n",
    "    print(\"DEBUG: Starting data cleaning and imputation for TRAINING\")\n",
    "    print(f\"Initial Polars DataFrame shape: {df.shape}\")\n",
    "    print(f\"Columns excluded from imputation (metadata/target): {EXCLUDE_COLS}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    initial_rows = df.shape[0]\n",
    "\n",
    "    missing_ratio = df.select([pl.col(c).is_null().mean()for c in df.columns if c not in EXCLUDE_COLS])\n",
    "    missing_dict = missing_ratio.to_dicts()[0]\n",
    "    too_missing = [col for col, ratio in missing_dict.items() if ratio > 0.3]\n",
    "    df = df.drop(too_missing)\n",
    "\n",
    "    print(f\"DEBUG: Highly missing columns dropped: {len(too_missing)}\")\n",
    "    print(f\"DEBUG: List of highly missing columns dropped: {too_missing}\")\n",
    "    print(f\"DEBUG: Shape after column drop: {df.shape}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    filter_condition = pl.all_horizontal([pl.col(c).is_not_null() for c in EXCLUDE_COLS])\n",
    "    df = df.filter(filter_condition)\n",
    "    rows_dropped = initial_rows - df.shape[0]\n",
    "    print(f\"DEBUG: Rows dropped due to NaN in critical columns: {rows_dropped}\")\n",
    "    print(f\"DEBUG: Shape after row drop: {df.shape}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "    all_feature_columns = [col for col in df.columns if col not in EXCLUDE_COLS]\n",
    "    print(f\"DEBUG: Total features to be imputed/used by model: {len(all_feature_columns)}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    df = df.with_columns([pl.col(col).cast(pl.Float64) for col in all_feature_columns])\n",
    "    print(\"DEBUG: Features successfully cast to Float64.\")\n",
    "\n",
    "    if 'date_id' in df.columns:\n",
    "        df = df.sort('date_id')\n",
    "        print(\"DEBUG: DataFrame sorted by 'date_id' for EWMA calculation.\")\n",
    "    else:\n",
    "        print(\"WARNING: 'date_id' not found. Assuming DataFrame is already sorted for EWMA.\")\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        [\n",
    "            pl.col(col).ewm_mean(span = EWMA_SPAN)\n",
    "            .forward_fill()\n",
    "            .fill_null(pl.col(col).mean())\n",
    "            for col in all_feature_columns\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"DEBUG: Imputation complete. All remaining NaNs in feature columns filled.\")\n",
    "    print(\"==================================================\")\n",
    "    return df, all_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7304ac5",
   "metadata": {
    "_cell_guid": "e62f0da6-75b6-4995-93e5-a2b8d385fc88",
    "_uuid": "d635398e-f483-4589-a1a8-06e029fab0f8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004605,
     "end_time": "2025-12-08T13:26:39.813320",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.808715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Imputation for test data**\n",
    "\n",
    "*(for training purpose only)*\n",
    "\n",
    "1. Filling NA on test data with EWMA mean\n",
    "2. If (first few rows) are NA, fill with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b31cb9",
   "metadata": {
    "_cell_guid": "f66f5aa4-1308-4c96-be36-2ff5aeb9f764",
    "_uuid": "6eb87b8b-5088-4c1f-b8e9-dd18142418de",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.824415Z",
     "iopub.status.busy": "2025-12-08T13:26:39.823530Z",
     "iopub.status.idle": "2025-12-08T13:26:39.829324Z",
     "shell.execute_reply": "2025-12-08T13:26:39.828637Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012618,
     "end_time": "2025-12-08T13:26:39.830550",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.817932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_and_impute_data_test_data(df: pl.DataFrame, feature_cols: List[str]):\n",
    "    \"\"\"\n",
    "    Handles missing values: imputes via EWMA/Mean.\n",
    "    \"\"\"\n",
    "    print(\"==================================================\")\n",
    "    print(\"DEBUG: Starting data cleaning and imputation for TESTING\")\n",
    "\n",
    "    if 'date_id' in df.columns:\n",
    "        df = df.sort('date_id')\n",
    "        print(\"DEBUG: DataFrame sorted by 'date_id' for EWMA calculation.\")\n",
    "    else:\n",
    "        print(\"WARNING: 'date_id' not found. Assuming DataFrame is already sorted for EWMA.\")\n",
    "        \n",
    "    df = df.with_columns(\n",
    "        [\n",
    "            pl.col(col).cast(pl.Float64).ewm_mean(span = EWMA_SPAN)\n",
    "            .forward_fill()\n",
    "            .fill_null(pl.col(col).mean())\n",
    "            for col in feature_cols\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"DEBUG: Imputation complete. All remaining NaNs in feature columns filled.\")\n",
    "    print(\"==================================================\")\n",
    "    return df, feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8799be",
   "metadata": {
    "_cell_guid": "e8ef4d1b-9fc4-48fe-9bb7-6bdc21a887ce",
    "_uuid": "f87b8349-79be-4544-a005-cb2bcd625aff",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004735,
     "end_time": "2025-12-08T13:26:39.840167",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.835432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Load Training Set**\n",
    "\n",
    "1. Load from csv\n",
    "2. Clean and impute data (call function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c660a15",
   "metadata": {
    "_cell_guid": "fc7fc8cb-2dc0-4589-a95c-2aa02da9479e",
    "_uuid": "eb211130-516d-403e-9728-7e99cdb2742c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.850975Z",
     "iopub.status.busy": "2025-12-08T13:26:39.850393Z",
     "iopub.status.idle": "2025-12-08T13:26:39.856453Z",
     "shell.execute_reply": "2025-12-08T13:26:39.855664Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013014,
     "end_time": "2025-12-08T13:26:39.857758",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.844744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trainset() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads, cleans, and returns the training data as a Pandas DataFrame for sklearn.\n",
    "    \"\"\"\n",
    "    print(\"==================================================\")\n",
    "    print(\"DEBUG: Starting training data loading process\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # Assuming DATA_PATH is defined\n",
    "    print (\"DEBUG: Reading training data from CSV...\")\n",
    "    try:\n",
    "        train_pl = pl.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "        print(f\"DEBUG: Initial Polars DataFrame shape: {train_pl.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load training data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    required_cols = EXCLUDE_COLS \n",
    "    print(f\"DEBUG: Required columns for metadata/target: {required_cols}\")\n",
    "\n",
    "    train_pl, _ = clean_and_impute_data_training(train_pl)\n",
    "    \n",
    "    print(\"DEBUG: Converting Polars DataFrame to Pandas...\")\n",
    "    train_pd = train_pl.to_pandas()\n",
    "    \n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"DEBUG: Final Pandas DataFrame shape: {train_pd.shape}\")\n",
    "    print(\"DEBUG: Training data loading and preparation complete.\")\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    return train_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047175c",
   "metadata": {
    "_cell_guid": "fc46257f-08ac-44bf-9cd2-9530e6043cc5",
    "_uuid": "c0222175-906f-4e96-a3a8-afdadb3ba4d7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004704,
     "end_time": "2025-12-08T13:26:39.867205",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.862501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Load Test Set**\n",
    "\n",
    "1. Load from csv\n",
    "2. Only get features based on feature selection in training phase\n",
    "3. Clean input (call function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832149dc",
   "metadata": {
    "_cell_guid": "b081177c-2749-4aa7-bb11-450059731b34",
    "_uuid": "2e2a6f3d-22b8-4f79-badb-e11dbfc082fd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.879218Z",
     "iopub.status.busy": "2025-12-08T13:26:39.878510Z",
     "iopub.status.idle": "2025-12-08T13:26:39.884269Z",
     "shell.execute_reply": "2025-12-08T13:26:39.883583Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012943,
     "end_time": "2025-12-08T13:26:39.885421",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.872478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_testset(features: List[str]) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the testing dataset for inference. \n",
    "    \"\"\"\n",
    "    print(\"==================================================\")\n",
    "    print(\"DEBUG: Starting test data loading process for inference\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    print (\"DEBUG: Reading test data from CSV...\")\n",
    "    try:\n",
    "        test_pl = pl.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "        print(f\"DEBUG: Initial Polars DataFrame shape: {test_pl.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load test data: {e}\")\n",
    "        return pl.DataFrame()\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    test_pl, _ = clean_and_impute_data_test_data(test_pl, features) \n",
    "    \n",
    "    print(\"DEBUG: Test data cleaning and imputation complete.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"DEBUG: Final Test DataFrame shape: {test_pl.shape}\")\n",
    "    print(\"DEBUG: Test data preparation complete.\")\n",
    "    print(\"==================================================\")\n",
    "\n",
    "    return test_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe941a5",
   "metadata": {
    "_cell_guid": "c78de016-3389-43d6-b4bf-d8780a007694",
    "_uuid": "c064e0f6-b58d-4714-9a43-a09b87ba5ab0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004386,
     "end_time": "2025-12-08T13:26:39.894510",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.890124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Sharpe Scoring**\n",
    "\n",
    "*from template / Competition Page*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980733df",
   "metadata": {
    "_cell_guid": "bc8cf839-784e-45c0-a1e7-7b151ee57f1c",
    "_uuid": "b9bdb96b-68ab-4b6e-a7da-9b3cf0aa7c49",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.905414Z",
     "iopub.status.busy": "2025-12-08T13:26:39.904988Z",
     "iopub.status.idle": "2025-12-08T13:26:39.913556Z",
     "shell.execute_reply": "2025-12-08T13:26:39.912922Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015694,
     "end_time": "2025-12-08T13:26:39.914737",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.899043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(submission['prediction']):\n",
    "        raise ParticipantVisibleError('Predictions must be numeric')\n",
    "\n",
    "    solution = solution.copy() # Need a copy when modifying, especially in PI scorer\n",
    "    solution['position'] = submission['prediction']\n",
    "\n",
    "    if solution['position'].max() > MAX_SIGNAL:\n",
    "        # In a real competition, this raises an error. For local scoring, we just proceed or clamp.\n",
    "        # Since the submission uses np.clip, this is primarily for validation/safety.\n",
    "        pass \n",
    "    if solution['position'].min() < MIN_SIGNAL:\n",
    "        pass\n",
    "\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "    \n",
    "    # Use product method for compounded mean excess return calculation\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    strategy_std = solution['strategy_returns'].std()\n",
    "\n",
    "    trading_days_per_yr = 252\n",
    "    if strategy_std == 0:\n",
    "        return 0.0\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    market_std = solution['forward_returns'].std()\n",
    "\n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    if market_volatility == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    return min(float(adjusted_sharpe), 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86c303",
   "metadata": {
    "_cell_guid": "712b08a3-54c9-4d1e-a7ea-ae4f9d7ccaaa",
    "_uuid": "0edd7b2a-8f4d-4afe-945a-29e0c407ac9f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.00464,
     "end_time": "2025-12-08T13:26:39.924175",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.919535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training / Fitting\n",
    "\n",
    "**Load Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11994a2c",
   "metadata": {
    "_cell_guid": "0252dfff-d5dc-4b03-988d-293189e9d3c6",
    "_uuid": "30224bdd-c24c-4e7d-81d2-cf128678abde",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:39.934948Z",
     "iopub.status.busy": "2025-12-08T13:26:39.934629Z",
     "iopub.status.idle": "2025-12-08T13:26:40.464027Z",
     "shell.execute_reply": "2025-12-08T13:26:40.462988Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.53677,
     "end_time": "2025-12-08T13:26:40.465614",
     "exception": false,
     "start_time": "2025-12-08T13:26:39.928844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DEBUG: Starting training data loading process\n",
      "--------------------------------------------------\n",
      "DEBUG: Reading training data from CSV...\n",
      "DEBUG: Initial Polars DataFrame shape: (9021, 98)\n",
      "--------------------------------------------------\n",
      "DEBUG: Required columns for metadata/target: ['date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\n",
      "==================================================\n",
      "DEBUG: Starting data cleaning and imputation for TRAINING\n",
      "Initial Polars DataFrame shape: (9021, 98)\n",
      "Columns excluded from imputation (metadata/target): ['date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\n",
      "--------------------------------------------------\n",
      "DEBUG: Highly missing columns dropped: 12\n",
      "DEBUG: List of highly missing columns dropped: ['E7', 'M1', 'M13', 'M14', 'M2', 'M5', 'M6', 'S12', 'S3', 'S8', 'V10', 'V9']\n",
      "DEBUG: Shape after column drop: (9021, 86)\n",
      "--------------------------------------------------\n",
      "DEBUG: Rows dropped due to NaN in critical columns: 0\n",
      "DEBUG: Shape after row drop: (9021, 86)\n",
      "--------------------------------------------------\n",
      "DEBUG: Total features to be imputed/used by model: 82\n",
      "--------------------------------------------------\n",
      "DEBUG: Features successfully cast to Float64.\n",
      "DEBUG: DataFrame sorted by 'date_id' for EWMA calculation.\n",
      "DEBUG: Imputation complete. All remaining NaNs in feature columns filled.\n",
      "==================================================\n",
      "DEBUG: Converting Polars DataFrame to Pandas...\n",
      "--------------------------------------------------\n",
      "DEBUG: Final Pandas DataFrame shape: (9021, 86)\n",
      "DEBUG: Training data loading and preparation complete.\n",
      "==================================================\n",
      "==================================================\n",
      "DEBUG: Performing time-series split (80/20, shuffle=False)...\n",
      "DEBUG: Split complete. \n",
      "\n",
      "Training Data Shapes:\n",
      "  X_train (Features ONLY): (7216, 82)\n",
      "  y_train (Target): (7216,)\n",
      "Validation Data Shapes:\n",
      "  X_val (Features ONLY): (1805, 82)\n",
      "  y_val (Target): (1805,)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_df_pd = load_trainset()\n",
    "features = [col for col in train_df_pd.columns if col not in EXCLUDE_COLS]\n",
    "metadata_cols = [col for col in EXCLUDE_COLS if col != TARGET_COL]\n",
    "\n",
    "X = train_df_pd.drop(columns=[TARGET_COL])\n",
    "y = train_df_pd[TARGET_COL]\n",
    "\n",
    "print((\"==================================================\"))\n",
    "print(\"DEBUG: Performing time-series split (80/20, shuffle=False)...\")\n",
    "X_train_meta, X_val_meta, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "X_train = X_train_meta[features]\n",
    "X_val = X_val_meta[features]\n",
    "print(f\"DEBUG: Split complete. \")\n",
    "print(f\"\\nTraining Data Shapes:\")\n",
    "print(f\"  X_train (Features ONLY): {X_train.shape}\")\n",
    "print(f\"  y_train (Target): {y_train.shape}\")\n",
    "print(f\"Validation Data Shapes:\")\n",
    "print(f\"  X_val (Features ONLY): {X_val.shape}\")\n",
    "print(f\"  y_val (Target): {y_val.shape}\")\n",
    "print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b1a27",
   "metadata": {
    "_cell_guid": "04bc7ef5-f704-4565-bcfd-528efaf3bfc5",
    "_uuid": "0d766251-f7f1-44b5-b424-a806a2eeece4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.005214,
     "end_time": "2025-12-08T13:26:40.476242",
     "exception": false,
     "start_time": "2025-12-08T13:26:40.471028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Choosing The Best Parameters for The Each Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8012a820",
   "metadata": {
    "_cell_guid": "981e43b9-1982-4d71-9db3-a01599ac8924",
    "_uuid": "4c5c321a-b353-4ec9-9531-0ee03a9fedd4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:40.487949Z",
     "iopub.status.busy": "2025-12-08T13:26:40.487598Z",
     "iopub.status.idle": "2025-12-08T13:26:40.503096Z",
     "shell.execute_reply": "2025-12-08T13:26:40.502139Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023354,
     "end_time": "2025-12-08T13:26:40.504583",
     "exception": false,
     "start_time": "2025-12-08T13:26:40.481229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model_optimization(\n",
    "    model_pipeline: Pipeline, \n",
    "    X_train_meta: pd.DataFrame,  \n",
    "    y_train: pd.Series,  \n",
    "    X_val_meta: pd.DataFrame, \n",
    "    y_val: pd.Series, \n",
    "    features: List[str] \n",
    ") -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Runs the entire feature selection (Discrete ASR PI + Top K) and model training \n",
    "    pipeline, performs Tanh signal sweep, and returns the best performing model info.\n",
    "    \"\"\"\n",
    "    X_train = X_train_meta[features].to_numpy()\n",
    "    X_val = X_val_meta[features].to_numpy()\n",
    "    y_val_np = y_val.to_numpy()\n",
    "\n",
    "    best_overall_sharpe = -np.inf\n",
    "    best_model_data = None\n",
    "    \n",
    "    # FIT BASE MODEL (Used for PI calculation)\n",
    "    base_pipeline = model_pipeline\n",
    "    base_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Prepare validation DF for sharpe ratio scoring \n",
    "    solution_val = pd.DataFrame({\n",
    "        'date_id': X_val_meta['date_id'].values,\n",
    "        'forward_returns': y_val.values,\n",
    "        'risk_free_rate': X_val_meta['risk_free_rate'].values\n",
    "    })\n",
    "    \n",
    "    # DEFINE DISCRETE ASR SCORER (Closure for Permutation Importance)\n",
    "    def discrete_asr_scorer_closure(estimator, X_subset, y_subset):\n",
    "        preds = estimator.predict(X_subset)\n",
    "        \n",
    "        # Apply Discrete Logic (Threshold = 0.001)\n",
    "        # 0 if pred <= 0, 1 if 0 < pred <= PI_SCORER_THRESHOLD, 2 otherwise\n",
    "        signals = np.where(preds <= 0, 0, np.where(preds <= PI_SCORER_THRESHOLD, 1, 2))\n",
    "        \n",
    "        sub_df = pd.DataFrame({'date_id': X_val_meta['date_id'], 'prediction': signals})\n",
    "        return score(solution_val, sub_df, 'date_id')\n",
    "\n",
    "    # CALCULATE PERMUTATION IMPORTANCE using Discrete ASR\n",
    "    print(f\"\\n--- Calculating PI using Discrete ASR Scorer (Threshold: {PI_SCORER_THRESHOLD:.4f}) ---\")\n",
    "    r = permutation_importance(\n",
    "        base_pipeline, \n",
    "        X_val, \n",
    "        y_val_np, \n",
    "        scoring=discrete_asr_scorer_closure, \n",
    "        n_repeats=10, \n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    feature_importances_mean = r.importances_mean\n",
    "    \n",
    "    if len(features) != len(feature_importances_mean):\n",
    "         raise ValueError(\"The length of the 'features' list does not match the size of importances_mean.\")\n",
    "        \n",
    "    imp = pd.DataFrame({\n",
    "        \"feature\": features,\n",
    "        \"importance\": feature_importances_mean\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "    \n",
    "    print(f\"DEBUG: Feature ranking complete. Top 5 features: {imp.head(5)['feature'].tolist()}\")\n",
    "    \n",
    "    # SWEEP OVER TOP K FEATURES\n",
    "    print(f\"\\n--- Starting Iteration over Top K Features: {TOP_K_OPTIONS} ---\") \n",
    "\n",
    "    for k in TOP_K_OPTIONS:\n",
    "        print(f\"\\n==================================================\")\n",
    "        print(f\"TOP K SWEEP: Testing Top K = {k}\")\n",
    "        print(f\"==================================================\")\n",
    "\n",
    "        selected_features = imp.head(k)[\"feature\"].tolist()\n",
    "\n",
    "        if len(selected_features) == 0:\n",
    "            print(\"No features selected (k=0). Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"DEBUG: Training with {len(selected_features)} features.\")\n",
    "        X_train_k = X_train_meta[selected_features].to_numpy()\n",
    "        X_val_k = X_val_meta[selected_features].to_numpy()\n",
    "\n",
    "        # Refit model on selected features\n",
    "        current_pipeline = clone(model_pipeline)\n",
    "        current_pipeline.fit(X_train_k, y_train)\n",
    "        y_pred = current_pipeline.predict(X_val_k)\n",
    "\n",
    "        mse = mean_squared_error(y_pred, y_val)\n",
    "        r2 = r2_score(y_pred, y_val)\n",
    "        \n",
    "        current_best_sharpe_for_k = -np.inf\n",
    "        optimal_pos = None\n",
    "        optimal_neg = None\n",
    "        \n",
    "        for pos in K_POS_OPTIONS:\n",
    "            for neg in K_NEG_OPTIONS:\n",
    "                # Tanh Transformation (1 + tanh(pred * K))\n",
    "                signals = np.where(\n",
    "                    y_pred < 0, \n",
    "                    1.0 + np.tanh(y_pred * neg), # Use K_NEG for negative predictions\n",
    "                    1.0 + np.tanh(y_pred * pos)  # Use K_POS for positive predictions\n",
    "                )\n",
    "                \n",
    "                signals_clipped = np.clip(signals, MIN_SIGNAL, MAX_SIGNAL)\n",
    "                current_submission = pd.DataFrame({\n",
    "                    'date_id': X_val_meta['date_id'].values, \n",
    "                    'prediction': signals_clipped \n",
    "                })\n",
    "                \n",
    "                current_sharpe = score(\n",
    "                    solution=solution_val, \n",
    "                    submission=current_submission, \n",
    "                    row_id_column_name='date_id'\n",
    "                )\n",
    "                \n",
    "                # Check Best Sharpe\n",
    "                if current_sharpe > current_best_sharpe_for_k:\n",
    "                    current_best_sharpe_for_k = current_sharpe\n",
    "                    optimal_pos = pos\n",
    "                    optimal_neg = neg\n",
    "                    \n",
    "        # Print and Check Overall Best Result for this iteration\n",
    "        print(f\"\\n--- BEST SIGNAL RESULTS for Top K={k} ---\\nðŸ¥‡ BEST ASR: {current_best_sharpe_for_k:.4f} (K_POS={optimal_pos}, K_NEG={optimal_neg})\")\n",
    "        \n",
    "        if current_best_sharpe_for_k > best_overall_sharpe:\n",
    "            best_overall_sharpe = current_best_sharpe_for_k\n",
    "            \n",
    "            # Save the current model and parameters as the best overall\n",
    "            best_model_data = {\n",
    "                'model': current_pipeline,\n",
    "                'features': selected_features,\n",
    "                'signal_k_pos': optimal_pos,\n",
    "                'signal_k_neg': optimal_neg,\n",
    "                'EWMA_SPAN': EWMA_SPAN,\n",
    "                'pi_discrete_threshold': PI_SCORER_THRESHOLD, # Store the PI scorer threshold\n",
    "                'top_k_used': k,\n",
    "                'mse': mse,\n",
    "                'r2': r2\n",
    "            }\n",
    "            print(f\"*** NEW OVERALL BEST ASR FOUND: {best_overall_sharpe:.4f} with Top K={k} ***\")\n",
    "            \n",
    "    print(\"\\n==================================================\")\n",
    "    print(f\"FINAL RESULT: Overall Best ASR: {best_overall_sharpe:.4f}\")\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    return best_overall_sharpe, best_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dc1a1d9",
   "metadata": {
    "_cell_guid": "df9fc351-6699-4402-9ef8-2ae0b017ca38",
    "_uuid": "258fbb8d-8fce-4a39-93d1-e7b5c8e99b4c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:26:40.516569Z",
     "iopub.status.busy": "2025-12-08T13:26:40.516017Z",
     "iopub.status.idle": "2025-12-08T13:36:31.043341Z",
     "shell.execute_reply": "2025-12-08T13:36:31.042146Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 590.534744,
     "end_time": "2025-12-08T13:36:31.044782",
     "exception": false,
     "start_time": "2025-12-08T13:26:40.510038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting HGBR Training Sweep for MAX_ITER=500 ---\n",
      "\n",
      "--- Calculating PI using Discrete ASR Scorer (Threshold: 0.0010) ---\n",
      "DEBUG: Feature ranking complete. Top 5 features: ['D1', 'D2', 'D3', 'D4', 'D5']\n",
      "\n",
      "--- Starting Iteration over Top K Features: [3, 5, 8, 10, 15] ---\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 3\n",
      "==================================================\n",
      "DEBUG: Training with 3 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=3 ---\n",
      "ðŸ¥‡ BEST ASR: -0.2105 (K_POS=10, K_NEG=500)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.2105 with Top K=3 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 5\n",
      "==================================================\n",
      "DEBUG: Training with 5 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=5 ---\n",
      "ðŸ¥‡ BEST ASR: 0.1731 (K_POS=200, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: 0.1731 with Top K=5 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 8\n",
      "==================================================\n",
      "DEBUG: Training with 8 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=8 ---\n",
      "ðŸ¥‡ BEST ASR: 0.0822 (K_POS=200, K_NEG=2000)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 10\n",
      "==================================================\n",
      "DEBUG: Training with 10 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=10 ---\n",
      "ðŸ¥‡ BEST ASR: -0.1227 (K_POS=75, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 15\n",
      "==================================================\n",
      "DEBUG: Training with 15 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=15 ---\n",
      "ðŸ¥‡ BEST ASR: 0.2375 (K_POS=200, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: 0.2375 with Top K=15 ***\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT: Overall Best ASR: 0.2375\n",
      "==================================================\n",
      "HGBR MAX_ITER=500 completed. Best Sharpe: 0.2375\n",
      "*** DEBUG: Found new best model! Previous Sharpe: -inf, New Sharpe: 0.2375 ***\n",
      "\n",
      "--- Starting HGBR Training Sweep for MAX_ITER=750 ---\n",
      "\n",
      "--- Calculating PI using Discrete ASR Scorer (Threshold: 0.0010) ---\n",
      "DEBUG: Feature ranking complete. Top 5 features: ['D1', 'D2', 'D3', 'D4', 'D5']\n",
      "\n",
      "--- Starting Iteration over Top K Features: [3, 5, 8, 10, 15] ---\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 3\n",
      "==================================================\n",
      "DEBUG: Training with 3 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=3 ---\n",
      "ðŸ¥‡ BEST ASR: -0.2262 (K_POS=10, K_NEG=500)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.2262 with Top K=3 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 5\n",
      "==================================================\n",
      "DEBUG: Training with 5 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=5 ---\n",
      "ðŸ¥‡ BEST ASR: 0.2015 (K_POS=10, K_NEG=1500)\n",
      "*** NEW OVERALL BEST ASR FOUND: 0.2015 with Top K=5 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 8\n",
      "==================================================\n",
      "DEBUG: Training with 8 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=8 ---\n",
      "ðŸ¥‡ BEST ASR: 0.0060 (K_POS=200, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 10\n",
      "==================================================\n",
      "DEBUG: Training with 10 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=10 ---\n",
      "ðŸ¥‡ BEST ASR: -0.1722 (K_POS=150, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 15\n",
      "==================================================\n",
      "DEBUG: Training with 15 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=15 ---\n",
      "ðŸ¥‡ BEST ASR: 0.0954 (K_POS=150, K_NEG=2000)\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT: Overall Best ASR: 0.2015\n",
      "==================================================\n",
      "HGBR MAX_ITER=750 completed. Best Sharpe: 0.2015\n",
      "*** DEBUG: Current Sharpe 0.2015 is not better than best Sharpe 0.2375. Skipping update. ***\n",
      "\n",
      "--- Starting HGBR Training Sweep for MAX_ITER=1000 ---\n",
      "\n",
      "--- Calculating PI using Discrete ASR Scorer (Threshold: 0.0010) ---\n",
      "DEBUG: Feature ranking complete. Top 5 features: ['D1', 'D2', 'D3', 'D4', 'D5']\n",
      "\n",
      "--- Starting Iteration over Top K Features: [3, 5, 8, 10, 15] ---\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 3\n",
      "==================================================\n",
      "DEBUG: Training with 3 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=3 ---\n",
      "ðŸ¥‡ BEST ASR: -0.2385 (K_POS=200, K_NEG=500)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.2385 with Top K=3 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 5\n",
      "==================================================\n",
      "DEBUG: Training with 5 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=5 ---\n",
      "ðŸ¥‡ BEST ASR: 0.2430 (K_POS=10, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: 0.2430 with Top K=5 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 8\n",
      "==================================================\n",
      "DEBUG: Training with 8 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=8 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0671 (K_POS=200, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 10\n",
      "==================================================\n",
      "DEBUG: Training with 10 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=10 ---\n",
      "ðŸ¥‡ BEST ASR: -0.1361 (K_POS=75, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 15\n",
      "==================================================\n",
      "DEBUG: Training with 15 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=15 ---\n",
      "ðŸ¥‡ BEST ASR: 0.0179 (K_POS=75, K_NEG=2000)\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT: Overall Best ASR: 0.2430\n",
      "==================================================\n",
      "HGBR MAX_ITER=1000 completed. Best Sharpe: 0.2430\n",
      "*** DEBUG: Found new best model! Previous Sharpe: 0.2375, New Sharpe: 0.2430 ***\n",
      "\n",
      "--- Starting HGBR Training Sweep for MAX_ITER=1250 ---\n",
      "\n",
      "--- Calculating PI using Discrete ASR Scorer (Threshold: 0.0010) ---\n",
      "DEBUG: Feature ranking complete. Top 5 features: ['D1', 'D2', 'D3', 'D4', 'D5']\n",
      "\n",
      "--- Starting Iteration over Top K Features: [3, 5, 8, 10, 15] ---\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 3\n",
      "==================================================\n",
      "DEBUG: Training with 3 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=3 ---\n",
      "ðŸ¥‡ BEST ASR: -0.2368 (K_POS=200, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.2368 with Top K=3 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 5\n",
      "==================================================\n",
      "DEBUG: Training with 5 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=5 ---\n",
      "ðŸ¥‡ BEST ASR: 0.1778 (K_POS=10, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: 0.1778 with Top K=5 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 8\n",
      "==================================================\n",
      "DEBUG: Training with 8 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=8 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0187 (K_POS=200, K_NEG=2000)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 10\n",
      "==================================================\n",
      "DEBUG: Training with 10 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=10 ---\n",
      "ðŸ¥‡ BEST ASR: -0.1040 (K_POS=10, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 15\n",
      "==================================================\n",
      "DEBUG: Training with 15 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=15 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0636 (K_POS=75, K_NEG=1000)\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT: Overall Best ASR: 0.1778\n",
      "==================================================\n",
      "HGBR MAX_ITER=1250 completed. Best Sharpe: 0.1778\n",
      "*** DEBUG: Current Sharpe 0.1778 is not better than best Sharpe 0.2430. Skipping update. ***\n",
      "\n",
      "--- Starting HGBR Training Sweep for MAX_ITER=1500 ---\n",
      "\n",
      "--- Calculating PI using Discrete ASR Scorer (Threshold: 0.0010) ---\n",
      "DEBUG: Feature ranking complete. Top 5 features: ['D1', 'D2', 'D3', 'D4', 'D5']\n",
      "\n",
      "--- Starting Iteration over Top K Features: [3, 5, 8, 10, 15] ---\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 3\n",
      "==================================================\n",
      "DEBUG: Training with 3 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=3 ---\n",
      "ðŸ¥‡ BEST ASR: -0.2293 (K_POS=200, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.2293 with Top K=3 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 5\n",
      "==================================================\n",
      "DEBUG: Training with 5 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=5 ---\n",
      "ðŸ¥‡ BEST ASR: 0.0542 (K_POS=10, K_NEG=1500)\n",
      "*** NEW OVERALL BEST ASR FOUND: 0.0542 with Top K=5 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 8\n",
      "==================================================\n",
      "DEBUG: Training with 8 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=8 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0254 (K_POS=200, K_NEG=2000)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 10\n",
      "==================================================\n",
      "DEBUG: Training with 10 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=10 ---\n",
      "ðŸ¥‡ BEST ASR: -0.1062 (K_POS=10, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 15\n",
      "==================================================\n",
      "DEBUG: Training with 15 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=15 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0329 (K_POS=75, K_NEG=2000)\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT: Overall Best ASR: 0.0542\n",
      "==================================================\n",
      "HGBR MAX_ITER=1500 completed. Best Sharpe: 0.0542\n",
      "*** DEBUG: Current Sharpe 0.0542 is not better than best Sharpe 0.2430. Skipping update. ***\n",
      "\n",
      "--- Starting HGBR Training Sweep for MAX_ITER=2000 ---\n",
      "\n",
      "--- Calculating PI using Discrete ASR Scorer (Threshold: 0.0010) ---\n",
      "DEBUG: Feature ranking complete. Top 5 features: ['D1', 'D2', 'D3', 'D4', 'D5']\n",
      "\n",
      "--- Starting Iteration over Top K Features: [3, 5, 8, 10, 15] ---\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 3\n",
      "==================================================\n",
      "DEBUG: Training with 3 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=3 ---\n",
      "ðŸ¥‡ BEST ASR: -0.2168 (K_POS=200, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.2168 with Top K=3 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 5\n",
      "==================================================\n",
      "DEBUG: Training with 5 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=5 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0617 (K_POS=10, K_NEG=1000)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.0617 with Top K=5 ***\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 8\n",
      "==================================================\n",
      "DEBUG: Training with 8 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=8 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0976 (K_POS=200, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 10\n",
      "==================================================\n",
      "DEBUG: Training with 10 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=10 ---\n",
      "ðŸ¥‡ BEST ASR: -0.1128 (K_POS=10, K_NEG=500)\n",
      "\n",
      "==================================================\n",
      "TOP K SWEEP: Testing Top K = 15\n",
      "==================================================\n",
      "DEBUG: Training with 15 features.\n",
      "\n",
      "--- BEST SIGNAL RESULTS for Top K=15 ---\n",
      "ðŸ¥‡ BEST ASR: -0.0053 (K_POS=50, K_NEG=2000)\n",
      "*** NEW OVERALL BEST ASR FOUND: -0.0053 with Top K=15 ***\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT: Overall Best ASR: -0.0053\n",
      "==================================================\n",
      "HGBR MAX_ITER=2000 completed. Best Sharpe: -0.0053\n",
      "*** DEBUG: Current Sharpe -0.0053 is not better than best Sharpe 0.2430. Skipping update. ***\n",
      "\n",
      "âœ“ Best model (Sharpe: 0.2430) saved to /tmp/model_data.joblib\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_sharpe = -np.inf # The minimum value\n",
    "\n",
    "\n",
    "for max_iter in MAX_ITER_OPTIONS:\n",
    "    \n",
    "    print(f\"\\n--- Starting HGBR Training Sweep for MAX_ITER={max_iter} ---\")\n",
    "    \n",
    "    hgbr_pipeline = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', HistGradientBoostingRegressor(\n",
    "            max_iter=max_iter,\n",
    "            learning_rate=HGBR_LEARNING_RATE,\n",
    "            max_depth=HGBR_MAX_DEPTH,\n",
    "            l2_regularization=HGBR_L2_REG,\n",
    "            early_stopping=HGBR_EARLY_STOPPING,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "  \n",
    "    sharpe, model_data = run_model_optimization(\n",
    "        model_pipeline=hgbr_pipeline,\n",
    "        X_train_meta=X_train_meta,\n",
    "        y_train=y_train,\n",
    "        X_val_meta=X_val_meta,\n",
    "        y_val=y_val,\n",
    "        features=features \n",
    "    )\n",
    "    \n",
    "    print(f\"HGBR MAX_ITER={max_iter} completed. Best Sharpe: {sharpe:.4f}\")\n",
    "    \n",
    "    if sharpe > best_sharpe:\n",
    "        print(f\"*** DEBUG: Found new best model! Previous Sharpe: {best_sharpe:.4f}, New Sharpe: {sharpe:.4f} ***\")\n",
    "        best_sharpe = sharpe\n",
    "        best_model = {\n",
    "            'model_type': 'HGBR',\n",
    "            'max_iter': max_iter,\n",
    "            'best_sharpe': sharpe,\n",
    "            'model_data' : model_data\n",
    "        }\n",
    "    else:\n",
    "        print(f\"*** DEBUG: Current Sharpe {sharpe:.4f} is not better than best Sharpe {best_sharpe:.4f}. Skipping update. ***\")\n",
    "\n",
    "if best_model and best_sharpe > -np.inf:\n",
    "    joblib.dump(best_model, MODEL_PATH)\n",
    "    print(f\"\\nâœ“ Best model (Sharpe: {best_sharpe:.4f}) saved to {MODEL_PATH}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ WARNING: No valid model found or best_sharpe not improved from initial value. Nothing saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ca30e",
   "metadata": {
    "_cell_guid": "798afb5a-4ac6-48ca-bcd9-af344fd4ba3c",
    "_uuid": "218dd4fb-6012-4e43-821a-4adcbf4748e1",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006881,
     "end_time": "2025-12-08T13:36:31.059243",
     "exception": false,
     "start_time": "2025-12-08T13:36:31.052362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict Function\n",
    "\n",
    "**Submission Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737a0068",
   "metadata": {
    "_cell_guid": "52d9e77e-8568-4732-912d-3eaa8380d3e6",
    "_uuid": "5e014dd4-2313-47c5-b63d-6ee27848cacb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-08T13:36:31.075074Z",
     "iopub.status.busy": "2025-12-08T13:36:31.074600Z",
     "iopub.status.idle": "2025-12-08T13:36:31.566702Z",
     "shell.execute_reply": "2025-12-08T13:36:31.564898Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.50249,
     "end_time": "2025-12-08T13:36:31.568608",
     "exception": false,
     "start_time": "2025-12-08T13:36:31.066118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting local predict DEMO (uses the local 'test.csv' copy)...\n",
      "\n",
      "â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸\n",
      "Model Data for Testing: \n",
      " {'model': Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 HistGradientBoostingRegressor(early_stopping=False,\n",
      "                                               l2_regularization=0.1,\n",
      "                                               learning_rate=0.05, max_depth=5,\n",
      "                                               max_iter=1000,\n",
      "                                               random_state=42))]), 'features': ['D1', 'D2', 'D3', 'D4', 'D5'], 'signal_k_pos': 10, 'signal_k_neg': 2000, 'EWMA_SPAN': 20, 'pi_discrete_threshold': 0.001, 'top_k_used': 5, 'mse': 0.00013221212175279363, 'r2': -14.68338442526505}\n",
      " â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸\n",
      "==================================================\n",
      "DEBUG: Starting test data loading process for inference\n",
      "--------------------------------------------------\n",
      "DEBUG: Reading test data from CSV...\n",
      "DEBUG: Initial Polars DataFrame shape: (10, 99)\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "DEBUG: Starting data cleaning and imputation for TESTING\n",
      "DEBUG: DataFrame sorted by 'date_id' for EWMA calculation.\n",
      "DEBUG: Imputation complete. All remaining NaNs in feature columns filled.\n",
      "==================================================\n",
      "DEBUG: Test data cleaning and imputation complete.\n",
      "--------------------------------------------------\n",
      "DEBUG: Final Test DataFrame shape: (10, 99)\n",
      "DEBUG: Test data preparation complete.\n",
      "==================================================\n",
      "DEBUG: Using Model Config: MaxIter=1000, TopK=5, PosK=10, NegK=2000\n",
      "==================================================\n",
      "DEBUG: Starting data cleaning and imputation for TESTING\n",
      "DEBUG: DataFrame sorted by 'date_id' for EWMA calculation.\n",
      "DEBUG: Imputation complete. All remaining NaNs in feature columns filled.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "âœ… FINAL VALIDATION ASR SCORE: 4.354760\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def predict(test: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Kaggle submission function compatible with the inference API.\n",
    "    Loads the best model and applies the optimized Tanh signal transformation.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(MODEL_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Model file not found at {MODEL_PATH}. Returning default position.\")\n",
    "        return pd.DataFrame({'date_id': test['date_id'], 'prediction': 1.0})\n",
    "\n",
    "    model_data = model['model_data']\n",
    "\n",
    "    print(f\"DEBUG: Using Model Config: MaxIter={model['max_iter']}, TopK={model_data['top_k_used']}, PosK={model_data['signal_k_pos']}, NegK={model_data['signal_k_neg']}\")\n",
    "    \n",
    "    # Clean & Prepare Features\n",
    "    features_to_use = model_data['features']\n",
    "    test_clean, _ = clean_and_impute_data_test_data(test, features_to_use)\n",
    "    \n",
    "    X_test_pl_features = test_clean.select(features_to_use)\n",
    "\n",
    "    # Predict Raw\n",
    "    predictions = model_data['model'].predict(X_test_pl_features.to_numpy())\n",
    "    \n",
    "    # Apply Tanh Signal Logic\n",
    "    signals = np.where(\n",
    "        predictions < 0, \n",
    "        1.0 + np.tanh(predictions * model_data['signal_k_neg']), \n",
    "        1.0 + np.tanh(predictions * model_data['signal_k_pos'])  \n",
    "    )\n",
    "                \n",
    "    signals_clipped = np.clip(signals, MIN_SIGNAL, MAX_SIGNAL)\n",
    "    \n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'date_id': test['date_id'], # Use date_id from the original test input\n",
    "        'prediction': signals_clipped\n",
    "    })  \n",
    "\n",
    "    return submission_df\n",
    "\n",
    "# =========================================================================\n",
    "# The code below is required for the Kaggle submission API\n",
    "# =========================================================================\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # This runs the local demo flow if not in the competition environment\n",
    "    def run_local_predict_demo():\n",
    "        print(\"\\nStarting local predict DEMO (uses the local 'test.csv' copy)...\")\n",
    "        \n",
    "        try:\n",
    "            model = joblib.load(MODEL_PATH)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Model file not found at {MODEL_PATH}. Cannot run demo.\")\n",
    "            return\n",
    "\n",
    "        model_data = model['model_data']\n",
    "\n",
    "        print(f\"\\nâ€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸\\nModel Data for Testing: \\n {model_data}\\n â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸\")\n",
    "        \n",
    "        # Load test set \n",
    "        X_test_pl = load_testset(features = model_data['features'])\n",
    "        \n",
    "        solution_val_df = pd.DataFrame({\n",
    "            'date_id': X_test_pl['date_id'].to_numpy(),\n",
    "            'forward_returns': X_test_pl['lagged_forward_returns'].to_numpy(),\n",
    "            'risk_free_rate': X_test_pl['lagged_risk_free_rate'].to_numpy()\n",
    "        })\n",
    "\n",
    "        submission_df = predict(X_test_pl)\n",
    "\n",
    "        final_asr_score = score(\n",
    "            solution=solution_val_df, \n",
    "            submission=submission_df,\n",
    "            row_id_column_name='date_id'\n",
    "        )\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"âœ… FINAL VALIDATION ASR SCORE: {final_asr_score:.6f}\")\n",
    "        print(\"==================================================\")\n",
    "        return\n",
    "\n",
    "    run_local_predict_demo()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14348714,
     "isSourceIdPinned": false,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 603.955342,
   "end_time": "2025-12-08T13:36:34.198294",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-08T13:26:30.242952",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
